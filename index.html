<!DOCTYPE html>
<html lang="pt-br">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Projeto Gemini</title>

  <!-- Ãcones do Material Design -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">

  <!-- CSS externo do projeto -->
  <link rel="stylesheet" href="style.css">

  <!-- Material Design Lite (estilo e componentes) -->
  <link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.indigo-pink.min.css">
  <script defer src="https://code.getmdl.io/1.3.0/material.min.js"></script>
</head>

<body>
  <!-- Layout principal com cabeÃ§alho fixo -->
  <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header">

    <!-- CabeÃ§alho -->
    <header class="mdl-layout__header">
      <div class="mdl-layout__header-row">
        <span class="mdl-layout-title">Gemini Live Demo</span>
      </div>
    </header>

    <!-- ConteÃºdo principal -->
    <main class="mdl-layout__content">
      <div class="page-content">
        <div class="demo-content">

          <!-- BotÃ£o para iniciar/pausar captura de Ã¡udio/vÃ­deo -->
          <div class="button-group">
            <button id="toggleButton"
                    class="mdl-button mdl-js-button mdl-button--fab mdl-button--mini-fab mdl-button--colored">
              <i class="material-icons">mic</i>
            </button>
          </div>

          <!-- Elementos de vÃ­deo e canvas ocultos -->
          <video id="videoElement" autoplay style="display: none;"></video>
          <canvas id="canvasElement" style="display: none;"></canvas>

          <!-- Log de mensagens ou chat -->
          <div id="chatLog"></div>

        </div>
      </div>
    </main>
  </div>

  <!-- Script principal -->
  <script> 
  const URL = "ws://localhost:9090";
      const video = document.getElementById("videoElement");
      const canvas = document.getElementById("canvasElement");
      let context;
      // VariÃ¡veis de estado
      let stream = null;
      let currentFrameB64;
      let webSocket = null;
      let audioContext = null;
      let processor = null;
      let pcmData = [];
      let interval = null;
      let initialized = false;
      let audioInputContext;
      let workletNode;
      let recording = false;

      // O que fazer quando a pÃ¡gina carregar
      window.addEventListener("load", async () => {
        context = canvas.getContext("2d");
        setInterval(captureImage, 3000);
        await startScreenShare();
        await initializeAudioContext();
        connect();
      });

      class Response {
        constructor(data) {
          this.text = data.text || null;
          this.audioData = data.audio || null;
        }
      }

      async function startScreenShare() {
        try {
          stream = await navigator.mediaDevices.getDisplayMedia({
            video: { width: { max: 640 }, height: { max: 480 } },
          }); // Definir resoluÃ§Ã£o mÃ¡xima
          video.srcObject = stream;
          await new Promise((resolve) => {
            video.onloadedmetadata = () => {
              resolve();
            };
          });
        } catch (err) {
          console.error("Error accessing the screen: ", err);
        }
      }

      function captureImage() {
        if (stream && video.videoWidth > 0) {
          context.drawImage(video, 0, 0, 640, 480);
          const imageData = canvas.toDataURL("image/jpeg").split(",")[1].trim();
          currentFrameB64 = imageData;
          console.log(
            "ðŸ“¸ IMAGEM CAPTURADA - Tamanho:",
            imageData.length,
            "bytes"
          ); 
        }
      }

      async function startAudioInput() {
        audioContext = new AudioContext({ sampleRate: 16000 });
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: { channelCount: 1, sampleRate: 16000 },
        });
        console.log("ðŸŽ™ï¸ STREAM DE ÃUDIO INICIADO - Sample Rate: 16000Hz");
        const source = audioContext.createMediaStreamSource(stream);
        processor = audioContext.createScriptProcessor(4096, 1, 1);
        processor.onaudioprocess = (e) => {
          const inputData = e.inputBuffer.getChannelData(0);
          const pcm16 = new Int16Array(inputData.length);
          for (let i = 0; i < inputData.length; i++) {
            pcm16[i] = inputData[i] * 0x7fff;
          }
          pcmData.push(...pcm16);
        };
        source.connect(processor);
        processor.connect(audioContext.destination);
        interval = setInterval(recordChunk, 3000);
      }

      function stopAudioInput() {
        if (processor) {
          processor.disconnect();
        }
        if (audioContext) {
          audioContext.close();
        }
        clearInterval(interval);
      }

      function recordChunk() {
        const buffer = new ArrayBuffer(pcmData.length * 2);
        const view = new DataView(buffer);
        pcmData.forEach((value, index) => {
          view.setInt16(index * 2, value, true);
        });
        const base64 = btoa(
          String.fromCharCode.apply(null, new Uint8Array(buffer))
        );
        console.log(
          "ðŸŽ¤ ÃUDIO CAPTURADO - Tamanho:",
          pcmData.length,
          "amostras, Base64:",
          base64.length,
          "chars"
        );
        sendVoiceMessage(base64);
        pcmData = [];
      }

      function sendVoiceMessage(b64PCM) {
        if (webSocket == null) {
          return;
        }
        const payload = {
          realtime_input: {
            media_chunks: [
              { mime_type: "audio/pcm", data: b64PCM },
              { mime_type: "image/jpeg", data: currentFrameB64 },
            ],
          },
        };
        webSocket.send(JSON.stringify(payload));
      }

      function connect() {
        webSocket = new WebSocket(URL);
        webSocket.onopen = () => {
          sendInitialSetupMessage();
        };
        webSocket.onmessage = receiveMessage;
        webSocket.onclose = () => {
          console.log("Connection closed");
        };
        webSocket.onerror = (err) => {
          console.error("WebSocket error:", err);
        };
      }

      function sendInitialSetupMessage() {
        const setupMessage = {
          setup: { generation_config: { response_modalities: ["AUDIO"] } },
        };
        webSocket.send(JSON.stringify(setupMessage));
      }

      function receiveMessage(event) {
        const messageData = JSON.parse(event.data);
        const response = new Response(messageData);
        if (response.text) {
          displayMessage("GEMINI: " + response.text);
        }
        if (response.audioData) {
          injestAudioChuckToPlay(response.audioData);
        }
      }

      async function initializeAudioContext() {
        if (initialized) return;
        audioInputContext = new (window.AudioContext ||
          window.webkitAudioContext)({
          sampleRate: 24000,
        });
        await audioInputContext.audioWorklet.addModule("pcm-processor.js");
        workletNode = new AudioWorkletNode(audioInputContext, "pcm-processor");
        workletNode.connect(audioInputContext.destination);
        initialized = true;
      }

      async function injestAudioChuckToPlay(base64AudioChunk) {
        try {
          if (audioInputContext.state === "suspended") {
            await audioInputContext.resume();
          }
          const arrayBuffer = base64ToArrayBuffer(base64AudioChunk);
          const float32Data = convertPCM16LEToFloat32(arrayBuffer);
          workletNode.port.postMessage(float32Data);
        } catch (error) {
          console.error("Error processing audio chunk:", error);
        }
      }

      function base64ToArrayBuffer(base64) {
        const binaryString = window.atob(base64);
        const bytes = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
          bytes[i] = binaryString.charCodeAt(i);
        }
        return bytes.buffer;
      }

      function convertPCM16LEToFloat32(pcmData) {
        const inputArray = new Int16Array(pcmData);
        const float32Array = new Float32Array(inputArray.length);
        for (let i = 0; i < inputArray.length; i++) {
          float32Array[i] = inputArray[i] / 32768;
        }
        return float32Array;
      }

      const toggleButton = document.getElementById("toggleButton");
      toggleButton.addEventListener("click", () => {
        if (recording) {
          stopAudioInput();
          recording = false;
          toggleButton.innerHTML = '<i class="material-icons">mic_off</i>';
        } else {
          startAudioInput();
          recording = true;
          toggleButton.innerHTML = '<i class="material-icons">mic</i>';
        }
      });

      function displayMessage(message) {
        console.log(message);
        addParagraphToDiv("chatLog", message);
      }

      function addParagraphToDiv(divId, text) {
        const newParagraph = document.createElement("p");
        newParagraph.textContent = text;
        const div = document.getElementById(divId);
        div.appendChild(newParagraph);
      }
  </script>
</body>
</html>
